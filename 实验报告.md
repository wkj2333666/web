# 实验报告
## 项目结构
/src: 源码（web除外）  
/data: 爬取的数据  
/analysis: 数据分析的结果  
/TestWeb: web前后端  

## 主要功能
### 爬虫部分
[singers_crawler.py](./src/singers_crawler.py) 爬取了200个歌手。  
[get_songs_from_singer.py](./src/get_songs_from_singer.py) 从以上得到的歌手列表上爬取歌曲，共9k余首。  
[get_song_info.py](./src/get_song_info.py) 和 [get_singer_info.py](./src/get_singer_info.py) 从上面得到的歌手与歌曲列表中，爬取详细的信息，包括评论、歌词、图片url等。  
[download_img.py](./src/download_img.py) 用于下载图片。  

以上，是所有用来爬取数据的脚本。下面的脚本用于对数据进行二次处理。  

[add_song_list_to_singer_info.py](./src/add_song_list_to_singer_info.py) 把歌曲列表加入 singer_info 中，从而建立起 singer 到 song 的映射。  
[change_id_to_dict.py](./src/change_id_to_dict.py) 把 song_info 中的 singer 存储形式从仅存储id转换成存储一个字典，更为详细，从而建立起 song 到 singer 的映射。  
[to_search_song.py](./src/to_search_song.py) 由于 song_info 本身信息很多，包括评论信息，不利于搜索。这个脚本把 song_info 中用于搜索的字段提炼出来。  

[song_pd2sql.ipynb](./src/song_pd2sql.ipynb) 和 [singer_pd2sql.ipynb](./src/singer_pd2sql.ipynb) 把数据从 DataFrame 形式转换成 Django 的 sqlite3 形式，供后端使用。  

以上是对数据的二次处理。

在爬虫过程中，发现有两个脚本数据量较大，爬取过程较慢，故又重写了异步版本，大幅提升了速度。  

[async_download_img.py](./src/async_download_img.py) 是 [download_img.py](./src/download_img.py) 的异步版本，把时间从2h压缩到1h。  
[async_get_song_info.py](./src/async_get_song_info.py) 是 [get_song_info.py](./src/get_singer_info.py) 的异步版本，把时间从5h压缩到40min。   

最后，有一个特殊的配置文件 [config.py](./src/config.py)，用于存放各种常量以及配置参数。(如cookie, header, workspace, url)  

### Web 部分
#### app
有4个app：
- HomePage：主页
- Search：搜索页及搜索功能
- SingerInfo：歌手列表及歌手详情页
- SongInfo：歌曲列表及歌曲详情页

#### 数据库
有3个table:
- SingerInfo_singer_info:
    - 定义：SingerInfo.models.singer_info
    - 来源：data/singer_info.json
- SongInfo_song_info:
    - 定义：SongInfo.models.song_info
    - 来源：data/song_info.json
- Search_search_song:
    - 定义：Search.models.search_song
    - 来源：data/song_search.json

#### 前端
- data/style.css: 是所有html模板的css  
- HomePage
    - home.html: 首页
- Search
    - search.html: 搜索页
    - singer.html: 歌手搜索结果页
    - song.html: 歌曲搜索结果页
- SingerInfo
    - singer_info.html：歌手详情页
    - singer_list.html: 歌手列表页
- SongInfo
    - song_info.html: 歌曲详情页
    - song_list.html: 歌曲列表页
  
#### 后端
各视图中的函数：
- HomePage
    - show_home: 渲染主页
- Search
    - search: 执行搜索，并跳转到歌手搜索结果页或歌曲搜索结果页
    - singer_result: 渲染歌手搜索结果页
    - song_result: 渲染歌曲搜索结果页
    - show_search_page: 渲染搜索页
- SingerInfo
    - show_singer_info: 渲染歌手详情页
    - show_singer_info_redirect: 在歌手详情页url缺少指定page时，跳转到第一页，即默认第一页
    - show_singer_list: 渲染歌手列表页
    - show_singer_list_redirect: 在歌手列表页url缺少指定page时，跳转到第一页，即默认第一页
    - goto_page: 跳转到指定页码
- SongInfo
    - show_song_info: 渲染歌曲详情页
    - show_song_info_redirect: 在歌曲详情页url缺少指定page时，跳转到第一页，即默认第一页
    - show_song_list: 渲染歌曲列表页
    - show_song_list_redirect: 在歌曲列表页url缺少指定page时，跳转到第一页，即默认第一页
    - goto_page: 跳转到指定页码
    - post_comment: 接收表单post，把新评论倒序插入数据库，重新渲染歌曲详情页
    - del_comment: 接收表单post，从数据库删除指定的评论，重新渲染歌曲详情页

### 数据分析部分

下面三个脚本用于数据分析。  

[wordcloud.py](./src/wordcloud.py) 用于评论区词云分析。  
[cover_most.py](./src/cover_most.py) 用于分析歌曲重复数。  
[date_rank.py](./src/date_rank.py) 用于分析歌曲上传年月的分布。  

## 使用的技术及算法
### 爬虫
- 常规技术
    - request 库爬取
    - re 正则表达式处理文本
    - bs4 处理 html
    - pandas 处理所得数据，聚类、过滤等
    - tqdm 进度条
- 加密
    - 网易云不直接接收爬取评论和歌词的 post 参数，而是接收加密后的参数。经调查，pyncm 包实现了相同的加密算法，故可以调用其中的 WeapiEncrypt 函数，处理原始参数再post，即可实现爬取。
- 异步
    - 在爬取大量数据的时候，CPU实际上有大量时间在等待网络回应，故造成效率的浪费。为了提高效率，这里采用异步编程，可以将迭代速率提升到 10it/s。
- swifter 加速 DataFrame 遍历
    - 众所周知，python for 循环效率极低，如果用 for loop 硬遍历 DataFrame，无疑是极慢的。pandas 的 apply 方法底层用 C 实现，故比 for loop 更快。此外，swifter 库可实现并行计算加速遍历。结合二者后，遍历速度可达 kit/s 量级。
- 重试与异常捕获
    - 经过上述优化，爬取速度大大加快，但被服务器反爬的风险也直线上升。这里采取 retry 机制，当抛出网络错误时，重新尝试连接，直至超出最大重试次数。retry 机制大大提升了爬虫的鲁棒性。
- 分块与多次爬取
    - 有时也难免避免脚本因服务器反爬而死掉，为了避免功亏一篑，这里采取分块爬取-保存机制。每当爬取了一个 chunk (设置为100个数据) 时，便自动保存数据。此外，爬取起点可手动设置，如此便可以实现“断点续连”。

### Web
- 模板
    - 通过模板可在前端实现一定的逻辑，如：遍历列表、拼接url
    - 通过 static 语法加载本地的图片
- 搜索
    - sqlite3 自带的 Q 过滤功能，性能很快
- CSS
    - 通过 CSS 可实现高级样式，如鼠标指向时变色、简单动画
- 表单
    - 通过 post 实现前后端的对话

### 数据分析
- 词云分析
    - jieba 进行分词
    - stopwords_sh 中文停用词，并加上了一些自定义停用词
    - wordcloud 进行词云图绘制
- 重复数统计
    - re 处理歌名
    - pandas groupby 聚类，统计每组数量
    - matplotlib 坐标轴标签倾斜
- 上传年月统计
    - 统一时间格式
    - matplotlib 设置坐标轴刻度及标签格式